
https://github.com/ollama/ollama

~~~
ollama serve
ollama run llama3.3
~~~


## WebUI

sudo apt install python3.11
sudo apt-get install python3.11-dev python3.11-venv

python3.11 -m venv ~/venv3.11
source  ~/venv3.11/bin/activate


pip install open-webui
open-webui serve
